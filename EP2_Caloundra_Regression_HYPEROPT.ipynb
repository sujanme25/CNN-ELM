{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy\n",
    "# Pytorch\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm, trange\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from hyperopt import hp, STATUS_OK\n",
    "from hyperopt import tpe, rand, anneal\n",
    "from hyperopt import Trials, fmin\n",
    "import warnings\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor as mlp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "import os\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "from math import sqrt\n",
    "from numpy import mean\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import catboost as ctb\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression,ElasticNet,Lasso,Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from hyperopt import hp, STATUS_OK\n",
    "import hyperopt.pyll.stochastic as hps\n",
    "from hyperopt import tpe, rand\n",
    "from hyperopt import Trials, fmin\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin, clone\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor,ExtraTreesRegressor,BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from hyperopt import hp, STATUS_OK\n",
    "from hyperopt import tpe, rand, anneal\n",
    "from hyperopt import Trials, fmin\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\SUJANPC\\\\Documents\\\\Energies\")\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import numpy\n",
    "from sklearn.neural_network import *\n",
    "from pandas import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "from sklearn.tree import *\n",
    "from catboost import *\n",
    "from sklearn.preprocessing import *\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import *\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import *\n",
    "import TSMETRICS\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.layers import *\n",
    "import time\n",
    "import optuna\n",
    "from optuna.study import *\n",
    "from optuna.trial import *\n",
    "import math\n",
    "import datetime\n",
    "import PIALL\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_excel('1D.xlsx',sheet_name='1D')\n",
    "df1= df.filter([\"Caloundra\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1\n",
    "lag =range(1,18)\n",
    "\n",
    "for col in df2.columns:\n",
    "    for l in lag:\n",
    "        df2.loc[:,col+\"_\"+str(l)] = df2[col].shift(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A= pd.read_excel('1D.xlsx',sheet_name='SILO_Caloundra')\n",
    "df_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B=df_A.drop(['YYYY-MM-DD'], axis=1)\n",
    "df_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_C=pd.concat([df2, df_B], axis=1, join='inner')\n",
    "df_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=df_C.dropna()\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=df5\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler() \n",
    "column_names_to_not_normalize = ['Caloundra']\n",
    "column_names_to_normalize = [x for x in list(df6) if x not in column_names_to_not_normalize ]\n",
    "x = df6[column_names_to_normalize].values\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = df6.index)\n",
    "df6[column_names_to_normalize] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df6.iloc[:,1:35]\n",
    "y=df6.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dod(real_values, pred_values):\n",
    "    dod_result=np.sqrt(np.mean((pred_values-real_values)**2))\n",
    "    return dod_result\n",
    "def objective(params):\n",
    "    params_copy = params.copy()\n",
    "    model_name = params_copy['model_name']\n",
    "    del params_copy['model_name']\n",
    "    if model_name == 'svm':\n",
    "        clf = SVR(**params_copy)\n",
    "    elif model_name == 'xgboost':\n",
    "        clf = xgb.XGBRegressor(**params_copy)\n",
    "    elif model_name == 'lightgbm':\n",
    "        clf = lgb.LGBMRegressor(**params_copy)\n",
    "    elif model_name == 'knn':\n",
    "        clf = KNeighborsRegressor(**params_copy)\n",
    "    elif model_name == 'Ridge':\n",
    "        clf = Ridge(**params_copy)\n",
    "    elif model_name == 'Lasso':\n",
    "        clf = Lasso(**params_copy)\n",
    "    elif model_name == 'KR':\n",
    "        clf = KernelRidge(**params_copy)\n",
    "    elif model_name == 'Enet':\n",
    "        clf = ElasticNet(**params_copy)\n",
    "    elif model_name == 'ADBR':\n",
    "        clf = AdaBoostRegressor(**params_copy)\n",
    "    elif model_name == 'RFR':\n",
    "        clf = RandomForestRegressor(**params_copy)\n",
    "    elif model_name == 'GPR':\n",
    "        clf = GaussianProcessRegressor(**params_copy)\n",
    "    elif model_name == 'DT':\n",
    "        clf = DecisionTreeRegressor(**params_copy)\n",
    "    elif model_name == 'MLP':\n",
    "        clf = MLPRegressor(**params_copy,\n",
    "                    batch_size='auto', learning_rate='adaptive',\n",
    "                     max_iter=25000, shuffle=False,tol=0.0001, verbose=False, warm_start=False, \n",
    "                           momentum=0.9, nesterovs_momentum=True, early_stopping=True, \n",
    "                           validation_fraction=0.1, beta_1=0.9,\n",
    "                           beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
    "    elif model_name == 'CTB':\n",
    "        clf = ctb.CatBoostRegressor(**params_copy,verbose=0,early_stopping_rounds=20)\n",
    "    elif model_name == 'ETR':\n",
    "        clf = ExtraTreesRegressor(**params_copy)\n",
    "    elif model_name == 'BGR':\n",
    "        clf = BaggingRegressor(base_estimator=SVR(),**params_copy)\n",
    "    elif model_name == 'SGD':\n",
    "        clf = SGDRegressor(max_iter=1000, tol=1e-3,**params_copy)\n",
    "        \n",
    "    else:\n",
    "        return 0\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    loss = dod(y_test, pred)\n",
    "    return {'loss':loss, 'params':params_copy, 'status':STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_space():\n",
    "    space_svm = {\n",
    "        'model_name': 'svm',\n",
    "        'kernel': hp.choice('kernel', ['rbf']),\n",
    "        'C':   hp.loguniform('C', -40,10 ),\n",
    "        'gamma':hp.loguniform('gamma', -40,10),\n",
    "        'epsilon':hp.quniform('epsilon', 1e-5,1e-1,1e-1),\n",
    "\n",
    "    }\n",
    "    space_knn = {\n",
    "        'model_name': 'knn',\n",
    "        'n_neighbors': hp.choice('n_neighbors', range(2,25)),\n",
    "        'algorithm': hp.choice('algorithm', ['auto','ball_tree','kd_tree','brute'])\n",
    "    }\n",
    "    space_xgboost = {\n",
    "        'model_name': 'xgboost',\n",
    "        'n_estimators': hp.choice('n_estimators', range(50,500,2)),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.1),\n",
    "        'max_depth': hp.choice('max_depth', range(2,80,1)),\n",
    "        'min_child_weight': hp.choice('min_child_weight', range(1,50,1)),\n",
    "        'reg_alpha': hp.uniform('reg_alpha', 0, 1.0),\n",
    "        'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0)\n",
    "    }\n",
    "    space_lightgbm = {\n",
    "        'model_name': 'lightgbm',\n",
    "        'n_estimators': hp.choice('n_estimators', range(50,500,2)),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': hp.choice('max_depth', range(2,80,1)),\n",
    "        'num_leaves': hp.choice('num_leaves', range(2, 50, 1)),\n",
    "        'min_child_weight': hp.uniform('min_child_weight', 0.001, 0.2),\n",
    "        'min_child_samples': hp.choice('min_child_samples', range(5,51,5)),\n",
    "        'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': hp.uniform('lgb_colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': hp.uniform('reg_alpha', 0, 1.0)\n",
    "    }\n",
    "    \n",
    "      \n",
    "    space_Lasso = {\n",
    "        'model_name': 'Lasso',\n",
    "        'alpha': hp.uniform('alpha', 0, 1.0)\n",
    "    }\n",
    "      \n",
    "    space_Ridge = {\n",
    "        'model_name': 'Ridge',\n",
    "        'alpha': hp.uniform('alpha', 0, 1.0)\n",
    "    }\n",
    "    \n",
    "      \n",
    "    space_KR = {\n",
    "        'model_name': 'KR',\n",
    "        'kernel': hp.choice('kernel', ['rbf']),\n",
    "        'alpha': hp.uniform('alpha', 0, 1.0)\n",
    "    }\n",
    "    \n",
    "    space_Enet = {\n",
    "        'model_name': 'Enet',\n",
    "        'l1_ratio': hp.uniform('l1_ratio', 0.1, 1.0),\n",
    "        'alpha': hp.uniform('alpha', 0, 1.0)\n",
    "    } \n",
    "    \n",
    "    space_ADBR = {\n",
    "        'model_name': 'ADBR',\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.0001, 0.3),\n",
    "        'loss':        hp.choice('loss', ['linear', 'square' ,'exponential']),\n",
    "        'n_estimators': hp.choice('n_estimators', range(5,800,2))\n",
    "    }\n",
    "    space_RFR = {\n",
    "        'model_name': 'RFR',\n",
    "        'n_estimators': hp.choice('n_estimators', range(5,800,2)),\n",
    "        'max_depth': hp.choice('max_depth', range(1,110,1)),\n",
    "        'min_samples_split': hp.choice('min_samples_split', range(2,100,1)),\n",
    "        'min_samples_leaf': hp.choice('min_samples_leaf', range(1,100,1)),\n",
    "        'max_features': hp.uniform('max_features', 0.4, 1.0)\n",
    "        }\n",
    "    \n",
    "    space_DT = {\n",
    "        'model_name': 'DT',\n",
    "        'max_depth':hp.choice('max_depth', range(1,200,1))\n",
    "        }\n",
    "\n",
    "    space_MLP = {\n",
    "        'model_name': 'MLP',\n",
    "        'hidden_layer_sizes': 50 + hp.randint('hidden_layer_sizes', 100),\n",
    "        'activation': hp.choice('activation', ['tanh', 'relu', 'logistic']),\n",
    "        'solver': hp.choice('solver', ['adam']),\n",
    "        'alpha': hp.uniform('alpha', 0.05, 1.0),\n",
    "        'learning_rate_init':hp.uniform('learning_rate_init', 0.01, 0.1)\n",
    "        }\n",
    "\n",
    "    space_CTB = {\n",
    "        'model_name': 'CTB',\n",
    "        'learning_rate':     hp.uniform('learning_rate', 0.01, 0.1),\n",
    "        'max_depth':         hp.choice('max_depth', range(1,16,1)),\n",
    "        'colsample_bylevel': hp.uniform('colsample_bylevel', 0.01, 1.0),\n",
    "        'n_estimators':      hp.choice('n_estimators', range(5,100,2))\n",
    "        }\n",
    "    space_ETR = {\n",
    "        'model_name': 'ETR',\n",
    "        'n_estimators': hp.choice('n_estimators', range(5,800,2)),\n",
    "        'max_depth': hp.choice('max_depth', range(1,110,1))\n",
    "        }\n",
    "    \n",
    "    return [space_svm, space_knn, space_xgboost, space_lightgbm,space_Lasso,space_Ridge,space_KR,space_Enet,\n",
    "            space_CTB,space_ADBR,space_RFR,space_DT,space_MLP,space_ETR]\n",
    "\n",
    "svm_params = {'kernel':['rbf']}\n",
    "knn_params = {'n_neighbors':range(2,25), 'algorithm':['auto','ball_tree','kd_tree','brute']}\n",
    "xgboost_params = {'n_estimators':range(50,500,2), 'max_depth':range(2,80,1), 'min_child_weight':range(1,50,1)}\n",
    "lightgbm_params = {'n_estimators':range(50,500,2), 'max_depth':range(2,80,1), 'num_leaves':range(2,50,1),\n",
    "                   'min_child_samples':range(5,51,5)}\n",
    "KR_params = {'kernel':['rbf']}\n",
    "CTB_params = {'n_estimators':range(5,100,2), 'max_depth':range(1,16,1)}\n",
    "ADBR_params = {'n_estimators':range(5,800,2), 'loss':['linear', 'square' ,'exponential']}\n",
    "RFR_params={'n_estimators': range(5,800,2), 'max_depth': range(1,110,1), \n",
    "            'min_samples_split': range(2,100,1), 'min_samples_leaf': range(1,100,1)}\n",
    "DT_params = {'max_depth':range(1,200,1)}\n",
    "MLP_params={'activation': ['logistic', 'tanh', 'relu'],'solver': ['adam']}\n",
    "ETR_params={'n_estimators': range(5,800,2), 'max_depth': range(1,110,1)}\n",
    "BGR_params={'n_estimators': range(5,800,2)}\n",
    "all_model_params = {'svm':svm_params, 'knn':knn_params, 'xgboost':xgboost_params, 'lightgbm':lightgbm_params,'KR':KR_params,\n",
    "                   'CTB':CTB_params,'ADBR':ADBR_params,'RFR': RFR_params,'DT':DT_params,'MLP':MLP_params,\n",
    "                   'ETR':ETR_params}\n",
    "spaces = create_space()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_params(spaces):\n",
    "    model_params = {}\n",
    "    MAX_EVALS = 50\n",
    "    for space in spaces:\n",
    "        trials = Trials()\n",
    "        best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=MAX_EVALS, trials=trials)\n",
    "        model_params[space['model_name']] = best_params\n",
    "    return model_params\n",
    "\n",
    "result = find_params(spaces)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Lasso':Lasso_params,'Ridge':Ridge_params,'Enet':Enet_params,'KR':KR_params\n",
    "def init_base_models(result):\n",
    "    result['svm']['kernel'] = all_model_params['svm']['kernel'][result['svm']['kernel']]\n",
    "    result['knn']['n_neighbors'] = all_model_params['knn']['n_neighbors'][result['knn']['n_neighbors']]\n",
    "    result['knn']['algorithm'] = all_model_params['knn']['algorithm'][result['knn']['algorithm']]\n",
    "    result['xgboost']['n_estimators'] = all_model_params['xgboost']['n_estimators'][result['xgboost']['n_estimators']]\n",
    "    result['xgboost']['max_depth'] = all_model_params['xgboost']['max_depth'][result['xgboost']['max_depth']]\n",
    "    result['xgboost']['min_child_weight'] = all_model_params['xgboost']['min_child_weight'][result['xgboost']['min_child_weight']]\n",
    "    result['lightgbm']['n_estimators'] = all_model_params['lightgbm']['n_estimators'][result['lightgbm']['n_estimators']]\n",
    "    result['lightgbm']['max_depth'] = all_model_params['lightgbm']['max_depth'][result['lightgbm']['max_depth']]\n",
    "    result['lightgbm']['num_leaves'] = all_model_params['lightgbm']['num_leaves'][result['lightgbm']['num_leaves']]\n",
    "    #result['Lasso']['alpha'] = all_model_params['Lasso']['alpha'][result['Lasso']['alpha']]\n",
    "    #result['Ridge']['alpha'] = all_model_params['Ridge']['alpha'][result['Ridge']['alpha']]\n",
    "    result['KR']['kernel'] = all_model_params['KR']['kernel'][result['KR']['kernel']]\n",
    "    #result['Enet']['alpha'] = all_model_params['Enet']['alpha'][result['Enet']['alpha']]\n",
    "    #result['Enet']['l1_ratio'] = all_model_params['Enet']['l1_ratio'][result['Enet']['l1_ratio']]\n",
    "    result['CTB']['n_estimators'] = all_model_params['CTB']['n_estimators'][result['CTB']['n_estimators']]\n",
    "    result['CTB']['max_depth'] = all_model_params['CTB']['max_depth'][result['CTB']['max_depth']]\n",
    "    result['ADBR']['n_estimators'] = all_model_params['ADBR']['n_estimators'][result['ADBR']['n_estimators']]\n",
    "    result['ADBR']['loss'] = all_model_params['ADBR']['loss'][result['ADBR']['loss']]\n",
    "    result['RFR']['n_estimators'] = all_model_params['RFR']['n_estimators'][result['RFR']['n_estimators']]\n",
    "    result['RFR']['max_depth'] = all_model_params['RFR']['max_depth'][result['RFR']['max_depth']]\n",
    "    result['RFR']['min_samples_split'] = all_model_params['RFR']['min_samples_split'][result['RFR']['min_samples_split']]\n",
    "    result['RFR']['min_samples_leaf'] = all_model_params['RFR']['min_samples_leaf'][result['RFR']['min_samples_leaf']]\n",
    "    result['GPR']['kernel'] = all_model_params['GPR']['kernel'][result['GPR']['kernel']]\n",
    "    result['DT']['max_depth'] = all_model_params['DT']['max_depth'][result['DT']['max_depth']]\n",
    "    result['MLP']['activation'] = all_model_params['MLP']['activation'][result['MLP']['activation']]\n",
    "    result['MLP']['solver'] = all_model_params['MLP']['solver'][result['MLP']['solver']]\n",
    "    result['MLP']['hidden_layer_sizes'] = all_model_params['MLP']['hidden_layer_sizes'][result['MLP']['hidden_layer_sizes']]\n",
    "    result['ETR']['n_estimators'] = all_model_params['ETR']['n_estimators'][result['ETR']['n_estimators']]\n",
    "    result['ETR']['max_depth'] = all_model_params['ETR']['max_depth'][result['ETR']['max_depth']]\n",
    "    result['BGR']['n_estimators'] = all_model_params['BGR']['n_estimators'][result['BGR']['n_estimators']]\n",
    "    \n",
    "    \n",
    "    svm = SVR(**result['svm'])\n",
    "    knn = KNeighborsRegressor(**result['knn'])\n",
    "    xgboost = xgb.XGBRegressor(**result['xgboost'])\n",
    "    lightgbm = lgb.LGBMRegressor(**result['lightgbm'])\n",
    "    LassoR =Lasso(alpha=result['Lasso']['alpha'])\n",
    "    RidgeR = Ridge(alpha=result['Ridge']['alpha'])\n",
    "    KRR= KernelRidge(**result['KR'])\n",
    "    CTBR=ctb.CatBoostRegressor(**result['CTB'],verbose=0,early_stopping_rounds=20)\n",
    "    ADBRR= AdaBoostRegressor(**result['ADBR'])\n",
    "    RFRR=RandomForestRegressor(**result['RFR'])\n",
    "    EnetR = ElasticNet(alpha=result['Enet']['alpha'],l1_ratio=result['Enet']['l1_ratio'])  \n",
    "    GPRR=GaussianProcessRegressor(**result['GPR'])\n",
    "    DTR=DecisionTreeRegressor(**result['DT'])\n",
    "    NNR=MLPRegressor(**result['MLP'],\n",
    "                    batch_size='auto', learning_rate='adaptive',\n",
    "                     max_iter=50000, shuffle=False,tol=0.0001, verbose=False, warm_start=False, \n",
    "                           momentum=0.9, nesterovs_momentum=True, early_stopping=True, \n",
    "                           validation_fraction=0.1, beta_1=0.9,\n",
    "                           beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
    "    ETRR= ExtraTreesRegressor(**result['ETR'])\n",
    "    BGRR=BaggingRegressor(base_estimator=SVR(),**result['BGR'])\n",
    "    SGDR = SGDRegressor(max_iter=1000, tol=1e-3,alpha=result['SGD']['alpha'])\n",
    "    return [svm, knn, xgboost, lightgbm, RidgeR, LassoR, EnetR, KRR,CTBR,ADBRR,RFRR,GPRR,DTR,NNR,ETRR,BGRR,SGDR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVR(**result['svm'])\n",
    "#knn = KNeighborsRegressor(**result['knn'])\n",
    "xgboost = xgb.XGBRegressor(**result['xgboost'])\n",
    "lightgbm = lgb.LGBMRegressor(**result['lightgbm'])\n",
    "#LassoR =Lasso(alpha=result['Lasso']['alpha'])\n",
    "#RidgeR = Ridge(alpha=result['Ridge']['alpha'])\n",
    "#KRR= KernelRidge(**result['KR'])\n",
    "CTBR=ctb.CatBoostRegressor(**result['CTB'],verbose=0,early_stopping_rounds=20)\n",
    "ADBRR= AdaBoostRegressor(**result['ADBR'])\n",
    "RFRR=RandomForestRegressor(**result['RFR'])\n",
    "#EnetR = ElasticNet(alpha=result['Enet']['alpha'],l1_ratio=result['Enet']['l1_ratio'])  \n",
    "#GPRR=GaussianProcessRegressor(**result['GPR'])\n",
    "DTR=DecisionTreeRegressor(**result['DT'])\n",
    "NNR=MLPRegressor(**result['MLP'],\n",
    "                batch_size='auto', learning_rate='adaptive',\n",
    "                 max_iter=50000, shuffle=False,tol=0.0001, verbose=False, warm_start=False, \n",
    "                       momentum=0.9, nesterovs_momentum=True, early_stopping=True, \n",
    "                       validation_fraction=0.1, beta_1=0.9,\n",
    "                       beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
    "ETRR= ExtraTreesRegressor(**result['ETR'])\n",
    "#SGDR = SGDRegressor(max_iter=1000, tol=1e-3,alpha=result['SGD']['alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVRR= SVR(C= 1412.9053582585025,\n",
    "epsilon= 0.1,\n",
    "gamma= 0.8016496032977202,\n",
    "kernel= 'rbf')\n",
    "\n",
    "KNNR= KNeighborsRegressor(algorithm='auto', n_neighbors= 13)\n",
    "\n",
    "XGBR=xgb.XGBRegressor(colsample_bytree= 0.7914433987177534,\n",
    "learning_rate= 0.05723755101429151,\n",
    "max_depth= 13,\n",
    "min_child_weight= 5,\n",
    "n_estimators= 140,\n",
    "reg_alpha= 0.6163416502525192,\n",
    "subsample= 0.5982401050462938)\n",
    "\n",
    "LGBR=lgb.LGBMRegressor(learning_rate= 0.07923591363613922,\n",
    "lgb_colsample_bytree= 0.6378087090013258,\n",
    "max_depth= 31,\n",
    "min_child_samples= 8,\n",
    "min_child_weight= 0.016240814758340785,\n",
    "n_estimators= 115,\n",
    "num_leaves= 11,\n",
    "reg_alpha= 0.5394653735096762,\n",
    "subsample= 0.9965057737609637)\n",
    "\n",
    "\n",
    "\n",
    "KRR= KernelRidge(alpha= 0.0030879873910933018, kernel= 'rbf')\n",
    "\n",
    "\n",
    "\n",
    "CTBR= ctb.CatBoostRegressor(colsample_bylevel= 0.7440259553630872,\n",
    "learning_rate= 0.09432613810717402,\n",
    "max_depth= 7,\n",
    "n_estimators= 34)\n",
    "\n",
    "ADBRR= AdaBoostRegressor(learning_rate= 0.25041138575518024,\n",
    "loss= 'exponential',\n",
    "n_estimators= 267,)\n",
    "\n",
    "RFRR= RandomForestRegressor(max_depth= 27,\n",
    "max_features= 0.4000025498244909,\n",
    "min_samples_leaf= 4,\n",
    "min_samples_split= 2,\n",
    "n_estimators= 233)\n",
    "\n",
    "\n",
    "NNR= MLPRegressor(activation= 'logistic',\n",
    "alpha= 0.9293500411939288,\n",
    "hidden_layer_sizes= 19,\n",
    "learning_rate_init= 0.03411181022612806,\n",
    "solver= 'adam')\n",
    "\n",
    "ETRR= ExtraTreesRegressor(max_depth= 34, n_estimators= 76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTBR.fit(X_train,y_train)\n",
    "ADBRR.fit(X_train,y_train)\n",
    "RFRR.fit(X_train,y_train)\n",
    "KNNR.fit(X_train,y_train)\n",
    "NNR.fit(X_train,y_train)\n",
    "ETRR.fit(X_train,y_train)\n",
    "XGBR.fit(X_train,y_train)\n",
    "LGBR.fit(X_train,y_train)\n",
    "SVRR.fit(X_train,y_train)\n",
    "KRR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_CTB_TEST=CTBR.predict(X_test)\n",
    "Y_pred_ADBR_TEST=ADBRR.predict(X_test)\n",
    "Y_pred_RFR_TEST=RFRR.predict(X_test)\n",
    "Y_pred_KNNR_TEST=KNNR.predict(X_test)\n",
    "Y_pred_MLP_TEST=NNR.predict(X_test)\n",
    "Y_pred_ETR_TEST=ETRR.predict(X_test)\n",
    "Y_pred_LGB_TEST=LGBR.predict(X_test)\n",
    "Y_pred_SVR_TEST=SVRR.predict(X_test)\n",
    "Y_pred_XGB_TEST=XGBR.predict(X_test)\n",
    "Y_pred_KRR_TEST=KRR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIALL\n",
    "y_test=np.array(y_test)\n",
    "PIALL_CTB=PIALL.PI(y_test,Y_pred_CTB_TEST)\n",
    "PIALL_ADBR=PIALL.PI(y_test,Y_pred_ADBR_TEST)\n",
    "PIALL_RFR=PIALL.PI(y_test,Y_pred_RFR_TEST)\n",
    "PIALL_KNNR=PIALL.PI(y_test,Y_pred_KNNR_TEST)\n",
    "PIALL_MLP=PIALL.PI(y_test,Y_pred_MLP_TEST)\n",
    "PIALL_ETR=PIALL.PI(y_test,Y_pred_ETR_TEST)\n",
    "PIALL_XGB=PIALL.PI(y_test,Y_pred_XGB_TEST)\n",
    "PIALL_SVR=PIALL.PI(y_test,Y_pred_SVR_TEST)\n",
    "PIALL_LGB=PIALL.PI(y_test,Y_pred_LGB_TEST)\n",
    "PIALL_KRR=PIALL.PI(y_test,Y_pred_KRR_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIALL_CTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIALL_ADBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIALL_RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIALL_KNNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIALL_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIALL_ETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIALL_SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIALL_XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIALL_LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\SUJANPC\\\\Documents\\\\Energies\\\\EP2\")\n",
    "TEST=pd.DataFrame([Y_pred_CTB_TEST,Y_pred_ADBR_TEST,Y_pred_RFR_TEST,\n",
    "                         Y_pred_KNNR_TEST,Y_pred_MLP_TEST,Y_pred_ETR_TEST,\n",
    "                        Y_pred_LGB_TEST,Y_pred_XGB_TEST,Y_pred_SVR_TEST,Y_pred_KRR_TEST,y_test]).T\n",
    "TEST.columns=['CTB','ADBR','RFR','KNNR','MLP','ETR','LGB','XGB','SVR','KRR','YTEST']\n",
    "writer = pd.ExcelWriter('EP2_Caloundra_REG.xlsx.xlsx', engine='xlsxwriter')\n",
    "TEST.to_excel(writer, sheet_name='TEST_Result')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, RMSprop,Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "cnn_lr_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                     patience=20, verbose=2, factor=0.7,min_delta = 1e-04, cooldown = 0,min_lr =0)\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=50),\n",
    "             ModelCheckpoint(filepath='best_weights_DNN_Caloundra.h5',verbose=2,\n",
    "                             monitor='val_loss', save_best_only=True),cnn_lr_reduction ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_keras_model():\n",
    "    model = Sequential([\n",
    "    Dense(320, activation=\"relu\",\n",
    "                       input_shape=(X_train.shape[1],)),\n",
    "    Dense(200, activation=tf.nn.relu),Dense(180, activation=tf.nn.relu),Dense(80, activation=tf.nn.relu),\n",
    "        Dense(60,activation=tf.nn.relu),Dense(40,activation=tf.nn.relu),Dense(30,activation=tf.nn.relu),\n",
    "    Dense(1)\n",
    "  ])\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5000\n",
    "BS=1\n",
    "model = dnn_keras_model()\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS,\n",
    "                  validation_split=0.2, verbose=2, batch_size=BS,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =load_model('best_weights_DNN_Caloundra.h5')\n",
    "model.summary()\n",
    "model_new = Model(inputs=model.input,outputs=model.get_layer('dense_7').output)\n",
    "y_test=np.array(y_test).flatten()\n",
    "Y_pred_DNN_TEST=model_new.predict(X_test).flatten()\n",
    "PIALL_DNN=PIALL.PI(y_test,Y_pred_DNN_TEST)\n",
    "PIALL_DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\SUJANPC\\\\Documents\\\\Energies\\\\EP2\")\n",
    "TEST=pd.DataFrame([Y_pred_CTB_TEST,Y_pred_ADBR_TEST,Y_pred_RFR_TEST,\n",
    "                         Y_pred_KNNR_TEST,Y_pred_MLP_TEST,Y_pred_ETR_TEST,\n",
    "                        Y_pred_LGB_TEST,Y_pred_XGB_TEST,Y_pred_SVR_TEST,Y_pred_KRR_TEST,Y_pred_DNN_TEST,y_test]).T\n",
    "TEST.columns=['CTB','ADBR','RFR','KNNR','MLP','ETR','LGB','XGB','SVR','KRR','DNN','YTEST']\n",
    "writer = pd.ExcelWriter('EP2_Caloundra_REG.xlsx.xlsx', engine='xlsxwriter')\n",
    "TEST.to_excel(writer, sheet_name='TEST_Result')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
